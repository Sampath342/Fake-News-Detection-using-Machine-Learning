{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type:ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# View the English stopwords that will be unnecessary for our analysis\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    news_df = pd.read_csv('IFND.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        news_df = pd.read_csv('IFND.csv', encoding='latin-1')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            news_df = pd.read_csv('IFND.csv', encoding='iso-8859-1')\n",
    "        except UnicodeDecodeError:\n",
    "            news_df = pd.read_csv('IFND.csv', encoding='cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = news_df.drop(columns=['Unnamed: 0', 'title'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Web</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>WHO praises India's Aarogya Setu app, says it ...</td>\n",
       "      <td>https://cdn.dnaindia.com/sites/default/files/s...</td>\n",
       "      <td>DNAINDIA</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Oct-20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>In Delhi, Deputy US Secretary of State Stephen...</td>\n",
       "      <td>https://cdn.dnaindia.com/sites/default/files/s...</td>\n",
       "      <td>DNAINDIA</td>\n",
       "      <td>VIOLENCE</td>\n",
       "      <td>Oct-20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>LAC tensions: China's strategy behind delibera...</td>\n",
       "      <td>https://cdn.dnaindia.com/sites/default/files/s...</td>\n",
       "      <td>DNAINDIA</td>\n",
       "      <td>TERROR</td>\n",
       "      <td>Oct-20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>India has signed 250 documents on Space cooper...</td>\n",
       "      <td>https://cdn.dnaindia.com/sites/default/files/s...</td>\n",
       "      <td>DNAINDIA</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Oct-20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Tamil Nadu chief minister's mother passes away...</td>\n",
       "      <td>https://cdn.dnaindia.com/sites/default/files/s...</td>\n",
       "      <td>DNAINDIA</td>\n",
       "      <td>ELECTION</td>\n",
       "      <td>Oct-20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          Statement  \\\n",
       "0   2  WHO praises India's Aarogya Setu app, says it ...   \n",
       "1   3  In Delhi, Deputy US Secretary of State Stephen...   \n",
       "2   4  LAC tensions: China's strategy behind delibera...   \n",
       "3   5  India has signed 250 documents on Space cooper...   \n",
       "4   6  Tamil Nadu chief minister's mother passes away...   \n",
       "\n",
       "                                               Image       Web  Category  \\\n",
       "0  https://cdn.dnaindia.com/sites/default/files/s...  DNAINDIA  COVID-19   \n",
       "1  https://cdn.dnaindia.com/sites/default/files/s...  DNAINDIA  VIOLENCE   \n",
       "2  https://cdn.dnaindia.com/sites/default/files/s...  DNAINDIA    TERROR   \n",
       "3  https://cdn.dnaindia.com/sites/default/files/s...  DNAINDIA  COVID-19   \n",
       "4  https://cdn.dnaindia.com/sites/default/files/s...  DNAINDIA  ELECTION   \n",
       "\n",
       "     Date Label  \n",
       "0  Oct-20  TRUE  \n",
       "1  Oct-20  TRUE  \n",
       "2  Oct-20  TRUE  \n",
       "3  Oct-20  TRUE  \n",
       "4  Oct-20  TRUE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe's first few entries\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "Statement        0\n",
       "Image            0\n",
       "Web              0\n",
       "Category         0\n",
       "Date         11321\n",
       "Label            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of null values in each column\n",
    "\n",
    "news_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill our Null values with an empty space\n",
    "\n",
    "news_df = news_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Target variable from the dataset\n",
    "\n",
    "X = news_df.drop(columns=['Image','Date','id','Label','Web','Category'], axis=1)\n",
    "Y = news_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHO praises India's Aarogya Setu app, says it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Delhi, Deputy US Secretary of State Stephen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAC tensions: China's strategy behind delibera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India has signed 250 documents on Space cooper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tamil Nadu chief minister's mother passes away...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56709</th>\n",
       "      <td>Fact Check: This is not Bruce Lee playing ping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56710</th>\n",
       "      <td>Fact Check: Did Japan construct this bridge in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56711</th>\n",
       "      <td>Fact Check: Viral video of Mexico earthquake i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56712</th>\n",
       "      <td>Fact Check: Ballet performance by Chinese coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56713</th>\n",
       "      <td>Fact Check: Is this little boy crossing into J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56714 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Statement\n",
       "0      WHO praises India's Aarogya Setu app, says it ...\n",
       "1      In Delhi, Deputy US Secretary of State Stephen...\n",
       "2      LAC tensions: China's strategy behind delibera...\n",
       "3      India has signed 250 documents on Space cooper...\n",
       "4      Tamil Nadu chief minister's mother passes away...\n",
       "...                                                  ...\n",
       "56709  Fact Check: This is not Bruce Lee playing ping...\n",
       "56710  Fact Check: Did Japan construct this bridge in...\n",
       "56711  Fact Check: Viral video of Mexico earthquake i...\n",
       "56712  Fact Check: Ballet performance by Chinese coup...\n",
       "56713  Fact Check: Is this little boy crossing into J...\n",
       "\n",
       "[56714 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        TRUE\n",
       "1        TRUE\n",
       "2        TRUE\n",
       "3        TRUE\n",
       "4        TRUE\n",
       "         ... \n",
       "56709    Fake\n",
       "56710    Fake\n",
       "56711    Fake\n",
       "56712    Fake\n",
       "56713    Fake\n",
       "Name: Label, Length: 56714, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming process\n",
    "p_stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the word to its original\n",
    "\n",
    "def clean_text(text):\n",
    "    text_cleaning_re = r\"@\\S+|https?://\\S+|http?://\\S|[^A-Za-z0-9]+\"\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    \n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['stemmed_statement'] = X['Statement'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['stemmed_statement'] = X['stemmed_statement'].fillna('')\n",
    "# Vectorizing using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X['stemmed_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (56714, 2)\n",
      "Shape of Y: (56714,)\n",
      "Unique values in Y: ['TRUE' 'Fake']\n"
     ]
    }
   ],
   "source": [
    "# Check the shape and unique values of the target labels (Y) to ensure data consistency\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "print(\"Unique values in Y:\", Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(X_tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split successfully!\n",
      "Shape of X_train: (45371, 2)\n",
      "Shape of X_test: (11343, 2)\n",
      "Shape of Y_train: (45371,)\n",
      "Shape of Y_test: (11343,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt to split the data into train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "    \n",
    "    # Check the shapes of the train and test sets\n",
    "    print(\"Data split successfully!\")\n",
    "    print(\"Shape of X_train:\", X_train.shape)\n",
    "    print(\"Shape of X_test:\", X_test.shape)\n",
    "    print(\"Shape of Y_train:\", Y_train.shape)\n",
    "    print(\"Shape of Y_test:\", Y_test.shape)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Print the error message if an error occurs during data splitting\n",
    "    print(\"Error occurred during data splitting:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training set, transform the test set\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train['stemmed_statement'])\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test['stemmed_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "decision_tree.fit(tfidf_train, Y_train)\n",
    "\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(decision_tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 91.92%\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = decision_tree.predict(tfidf_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'Decision Tree Accuracy: {round(accuracy * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_dt(input_text):\n",
    "    input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "    prediction = decision_tree.predict(input_tfidf)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = 'Narendra Modi is India Prime Minister'\n",
    "print(predict_label_dt(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.fit(tfidf_train, Y_train)\n",
    "\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(logistic_regression, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 93.48%\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = logistic_regression.predict(tfidf_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'Logistic Regression Accuracy: {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_logistic(input_text):\n",
    "    input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "    prediction = logistic_regression.predict(input_tfidf)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "input = 'Narendra Modi is India Prime Minister'\n",
    "print(predict_label_logistic(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(tfidf_train, Y_train)\n",
    "\n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 87.91%\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = knn.predict(tfidf_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'KNN Accuracy: {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_knn(input_text):\n",
    "    input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "    prediction = knn.predict(input_tfidf)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake\n"
     ]
    }
   ],
   "source": [
    "input = 'Narendra Modi is India Prime Minister'\n",
    "print(predict_label_knn(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
